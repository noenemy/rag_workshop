** 실습 4. 웹 크롤러 실습

4.1 Web Crawler Connector 이용하기

앞에서 만든 Amazon Q Business 애플리케이션에 웹 사이트의 내용을 크롤링한 후에 결과를 생성하는 예제를 실습해보겠습니다.

1. Add Data sources 버튼을 클릭합니다.

2. Web crawler 를 선택합니다.

3. Data source name 에 webcrawler 라고 입력합니다.

4. Source URL을 선택하고 다음 URL 들을 추가합니다. 

Authentication 섹션 선택하기. 기본값은 No authentication 둡니다.
Web proxy와 Configure VPC and security group - optional 에 대한 설명 필요

5. IAM role 을 선택하고, DataSourceRole을 생성합니다. (TODO: 필요한 권한을 추가해서 Role 만들기)

6. Sync scope 섹션 항목들을 다음과 같이 설정합니다.
- Sync range : Sync domains with subdomains only
- Crawl depth : 0 
- Maximum links per page : 1
(TODO : 각 항목들에 대한 설명 필요)

7. Sync run schedule 섹션의 항목을 다음과 같이 설정합니다.
- Frequency : Run on demand
(TODO: 상세 내용 설명) 

8. Add data source를 클릭합니다.

9. Sync now를 선택해서 웹 크롤링으로 인덱싱을 시작합니다. 

10. Amazon Q Application에서 사용할 수 있도록 인덱싱 작업이 진행됩니다. 이 과정은 10-15 분이 소요됩니다. 

11. 브라우저를 새로 고침해보면 Status Details 가 Read to use a source라고 표시되면 인덱싱 작업이 준비된 것입니다.

인덱싱 작업이 완료될 때까지 잠시 기다립니다. 

인덱싱 작업이 진행되는 동안 워크샵 진행 안내에 따르시기 바랍니다. 
실습 상황에 따라서 쉬는 시간으로 활용되거나 또는 별도의 기술 설명이 진행될 수 있습니다.


** 4.2 Q Business 애플리케이션 이용하기

1. Web Experience 탭의 Deployed URL 값을 복사합니다.

2. 웹 브라우저의 주소창에 복사한 URL 값을 입력하면 다음과 같이 화면이 보여집니다.


Q Business 앱 이미지

~~~
Where is Yosemite national park located?
~~~

~~~
When was it founded?
~~~

~~~
What are the important points to see there?
~~~

이미지들

예제 문장 


~~~
Whats the best time to visit Yosemite?
~~~

~~~
What are the flora and fauna found there?
~~~

이미지들

~~~
Create a flyer for Yosemite visitors based on this conversation
~~~

Amazon Q를 이용한 Upload files, Web crawler 예제를 실습하였습니다.




